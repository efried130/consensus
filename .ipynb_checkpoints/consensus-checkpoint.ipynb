{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74fb9108-640a-4a61-ad2b-c55ee438fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from netCDF4 import Dataset,chartostring\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b680093-88ac-4015-a773-e23d4382c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish mnt and important data locations in reference to mnt\n",
    "mnt=Path('/fs/ess/PAS1926/Fix_SWOT_SHCQ/confluence_latest/latest_mnt')\n",
    "confluence_input=mnt.joinpath('input')\n",
    "flpedir=mnt.joinpath('flpe')\n",
    "output=flpedir.joinpath('consensus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcd25a85-ffb6-4360-ae8a-e8d056b1cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo_metadata():\n",
    "        algos={\n",
    "            'momma': {\n",
    "                'qvar':'Q'\n",
    "            },\n",
    "            'hivdi': {\n",
    "                'qvar':'Q'\n",
    "            },\n",
    "            'neobam':{\n",
    "                'qvar':'q/q'\n",
    "            },\n",
    "            'metroman':{\n",
    "                'qvar':'allq'\n",
    "            },\n",
    "            'sic4dvar':{\n",
    "                'qvar':'Q_da'\n",
    "            },\n",
    "            'sad':{\n",
    "                'qvar':'Qa'\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c4c5658-3d40-4a3c-9afe-c8307885d4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(reach_id,flpedir,MD):\n",
    "    FLPEs_to_check=os.listdir(flpedir)\n",
    "    q=[]\n",
    "    flpe=[]\n",
    "    for ALGO in FLPEs_to_check:\n",
    "        if ALGO !='consensus':\n",
    "            if ALGO !='lakeflow': #avoide possibly recursivly generating consensus, or ever including lakeflow\n",
    "                NOWdir=flpedir.joinpath(ALGO)\n",
    "                FN=str(reach_id)+'_'+ALGO+'.nc'\n",
    "                try:\n",
    "                    D=Dataset(NOWdir.joinpath(FN))\n",
    "                    algoQ=D[MD[ALGO]['qvar']][:].filled(np.nan)\n",
    "                    q.append(algoQ)\n",
    "                    flpe.append(ALGO)\n",
    "                    \n",
    "                        \n",
    "                except:\n",
    "                    optional_print=False\n",
    "                    if optional_print:\n",
    "                        print('no '+ALGO+' discharge file at '+str(reach_id))\n",
    "        flpedict={\n",
    "        'rid':reach_id,\n",
    "        'q':q,\n",
    "        'FLPEs':flpe\n",
    "    }\n",
    "        \n",
    "    return flpedict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e2a17c-c362-49e8-b2b9-f523e65d6eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_low_cv_and_calc_consensus(arrs, CV_thresh):\n",
    "    \"\"\"\n",
    "    For a list of discharge arrays:\n",
    "    - Removes arrays with CV < threshold\n",
    "    - Recalculates consensus using the remaining arrays\n",
    "    Parameters\n",
    "    ----------\n",
    "    arrs : list of np.ndarray\n",
    "        Discharge arrays from each algorithm.\n",
    "    CV_thresh : float\n",
    "        Coefficient of variation threshold below which arrays are excluded.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Cleaned and recalculated consensus array.\n",
    "    \"\"\"\n",
    "    cleaned_arrs = []\n",
    "    for arr in arrs:\n",
    "        mean = np.nanmean(arr)\n",
    "        std = np.nanstd(arr)\n",
    "        cv = std / mean if mean != 0 else np.nan\n",
    "        if not np.isnan(cv) and cv > CV_thresh:\n",
    "            cleaned_arrs.append(arr)\n",
    "\n",
    "    if not len(cleaned_arrs):\n",
    "        print(\"All algorithms removed due to low CV; returning NaN array.\")\n",
    "        return np.full_like(arrs[0], np.nan)\n",
    "\n",
    "    return np.nanmedian(np.stack(cleaned_arrs, axis=0), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ac383e-ff32-42a6-a960-6a484a06277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_consensus(indict):\n",
    "    \n",
    "    conlen=len(indict['q'][0])\n",
    "    #Calculate median based consensus\n",
    "    ALLQ=np.full((len(indict['q']),  conlen), np.nan)\n",
    "    \n",
    "    contributed=[]\n",
    "    for row in range(len(indict['q'])):\n",
    "        ALGv=indict['q'][row]\n",
    "        if np.size(ALGv)==conlen:\n",
    "            ALLQ[row,:]=ALGv\n",
    "            if np.any(ALGv>0):\n",
    "                contributed.append(indict['FLPEs'][row])\n",
    "        \n",
    "    \n",
    "    consensus=np.nanmedian(ALLQ,axis=0)\n",
    "    consensus_cv=remove_low_cv_and_calc_consensus([ALLQ[i, :] for i in range(ALLQ.shape[0])], CV_thresh=0.5)\n",
    "        \n",
    "        \n",
    "    consensus_dictionary={\n",
    "            'rid':indict['rid'],\n",
    "            'q_all':consensus,\n",
    "            'q':consensus_cv,\n",
    "            'FLPEs':contributed,\n",
    "            'n_contributers':len(contributed)\n",
    "        }\n",
    "    return consensus_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fe3d40e-0b06-4181-87a7-0f64328080ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_consensus(indict,output_dir):\n",
    "    reach_id=indict['rid']\n",
    "    nt=len(indict['q'])\n",
    "    # output     \n",
    "    outfile= os.path.join(output_dir, f'{reach_id}_consensus.nc')\n",
    "    dsout = Dataset(outfile, 'w', format=\"NETCDF4\") #output dataset\n",
    "    dsout.n_algos=str(indict['n_contributers'])\n",
    "    dsout.contributing_algos=indict['FLPEs']\n",
    "    dsout.createDimension(\"nt\",nt)\n",
    "    fillvalue = np.nan\n",
    "    consensus_q= dsout.createVariable(\"consensus_q\",\"f8\",(\"nt\"),fill_value=fillvalue)\n",
    "    consensus_q.long_name= 'consensus discharge'\n",
    "    consensus_q[:]=indict['q']\n",
    "    dsout.close\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "933dc749-1388-429f-978f-d87a27574127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.37231068/ipykernel_1407845/264081091.py:16: RuntimeWarning: All-NaN slice encountered\n",
      "  consensus=np.nanmedian(ALLQ,axis=0)\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "\n",
    "#read the input reaches.json file that is driving the entire run\n",
    "reach_list=confluence_input.joinpath('reaches.json')\n",
    "try:\n",
    "    with open(reach_list, 'r') as file:\n",
    "        RL = json.load(file)        \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'reaches.json' not found. Please ensure the file exists.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Error: Could not decode JSON from 'reaches.json'. Check file format.\")\n",
    "#loop through reaches in the list and calculate consensus for each\n",
    "MetaData=algo_metadata()#this function generated a dictionary of q variables from the various FLPEs\n",
    "for reach in RL:   \n",
    "    rid=reach['reach_id']\n",
    "    FLPEdict=collect_data(rid,flpedir,MetaData)#generates a dictionary of all FLPEs at that reach\n",
    "    CONdict=calculate_consensus(FLPEdict)#generates a dictionary of consensus and metadata\n",
    "    write_consensus(CONdict,output)#writes file with consensus to flpe directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-swotEF]",
   "language": "python",
   "name": "conda-env-.conda-swotEF-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
